[{"title":"Hello World","url":"/2025/08/23/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n"},{"title":"Hexo 写博客指南","url":"/2025/08/26/post001/","content":"Hexo 写博客指南这是一份面向新手和进阶用户的 Hexo 写作指南，整合了常见问题与一些经验。内容涵盖目录结构、文章写作、分类标签管理、草稿发布以及部署方式等。\n1. Hexo 目录结构一个典型的 Hexo 博客目录：\n\n\n\n_posts&#x2F;：专门放文章，Hexo 会根据 Front-matter 自动生成分类、标签、归档。\nsource&#x2F;xxx&#x2F;：放置独立页面，比如关于、友链、相册等。\nscaffolds&#x2F;：定义 hexo new 时文章的默认模板。\nthemes&#x2F;：主题目录，可以自定义样式与功能。\n\n2. 写文章的基本操作新建文章hexo new post &quot;我的第一篇文章&quot;\n\n文章头部 Front-matter---title: 我的第一篇文章date: 2025-10-10 15:00:00categories: 学习tags: [Hexo, 教程]---\n\n草稿写作hexo new draft &quot;草稿文章&quot;\n\n草稿会保存在 source/_drafts/ 下。发布草稿：\nhexo publish draft &quot;草稿文章&quot;\n\n3. 分类 &#x2F; 标签 &#x2F; 归档文章中的分类与标签categories: 技术tags: [Hexo, Node.js, git]\n\n\n分类 有层级关系（categories: [技术, 前端]）。\n标签是 自由标签，无层级。\n\n分类、标签、归档页面Hexo 不会自动生成 /categories/、/tags/、/archives/ 页面，需要手动新建：\nhexo new page categorieshexo new page tagshexo new page archives\n\n修改生成的 index.md：\n---title: 分类type: categories------title: 标签type: tags------title: 归档type: archives---\n\n这样访问 /categories/ 就能显示分类索引。\n4. 独立页面如果你在菜单里配置了页面入口，就需要在 source/ 下新建对应文件夹：\n例如：\nmenu:  主页: / || fas fa-home  生活 || fas fa-list:    相册: /photos/ || fa fa-camera-retro    音乐: /music/ || fa fa-music\n\n则需要建：\nsource/photos/index.mdsource/music/index.md\n\n5. 部署博客常用命令hexo clean    # 清理缓存和 public/hexo g        # 生成静态文件hexo s        # 本地启动预览hexo d        # 部署到远程\n\nGit 部署在 _config.yml 里配置：\ndeploy:  type: git  repo: git@github.com:用户名/用户名.github.io.git  branch: master\n\n安装部署插件：\nnpm install hexo-deployer-git --save\n\n执行：\nhexo clean &amp;&amp; hexo g &amp;&amp; hexo d\n\n","categories":["教程","Hexo"],"tags":["Hexo"]},{"title":"Hexo + GitHub 搭建个人博客","url":"/2025/08/25/post002/","content":"Hexo + GitHub 搭建个人博客\n\n一、前言1. HexoHexo 是一个快速、简洁且高效的博客框架，它能够将 Markdown 格式的文档解析并渲染为静态网页，从而方便地构建和部署个人博客。\n2. GitHub 与 GitHub PagesGitHub 作为全球知名的代码托管平台，大家应该都有所了解。而在本次搭建过程中，我们将重点使用其提供的 GitHub Pages 服务。\n什么是 GitHub Pages？简单来说，GitHub Pages 可以将托管在 GitHub 仓库中的静态代码（HTML、CSS、JS）渲染成可访问的网页。\n如何使用？GitHub 为每个账户提供了一个特殊的仓库，专门用于托管个人站点。该仓库的命名规则必须为 username.github.io（其中 username 替换为你的 GitHub 用户名）。\n访问方式：当你将博客内容上传至该仓库后，即可通过 https://username.github.io 访问你的个人博客。\n\n例如：如果用户名是 kenzieliu，访问地址就是 https://kenzieliu.github.io。\n\n二、准备工作1. 注册 GitHub需要有一个 GitHub 账号，没有的话可以去 官网 注册一个。\n\n\n2. 安装GitGit 是一个开源的分布式版本控制系统，可高效管理从小型到大型项目的版本变更。\n下载和安装可前往 Git 官网 获取安装包。下载完成后，双击安装程序，按照提示一路点击 “Next” 进行默认安装即可。安装完成后，在任意文件夹内右键若出现 “Git Bash Here” 选项（这是 Git 的命令行工具），则说明 Git 已成功安装。\n\n\n\n\n设置用户名和邮箱由于 Git 是分布式版本控制系统，在进行代码提交前需要设置用户名和邮箱作为提交者的身份标识。可在命令行中输入以下命令进行配置：\ngit config --global user.name &quot;user_name&quot; # user_name 填入 GitHub 用户名git config --global user.email &quot;user_email&quot; # user_email 填入 GitHub 注册的邮箱\n\n3. 安装Node.js进入 Node官网 下载最新稳定版本，然后参考 安装教程 进行安装即可。\n\n\n安装 Node.js 会包含环境变量以及 npm 的安装，安装后，可以在命令行输入如下命令检测 Node.js 是否安装成功：\n#在 nodejs 安装成功的情况下会显示 nodejs 的版本号node -v #在 nodejs 安装成功的情况下会显示 npm 的版本号npm -v\n\n将 npm 修改为国内源，以便于正常使用：\n#修改为淘宝镜像源npm config set registry https://registry.npmmirror.com\n\n三、创建仓库登录 GitHub 账号，新建一个名为 username.github.io（这里的 username 要替换成自己的实际的用户名） 的仓库。\n\n\n\n\n如上图，点击 New repository 按钮，进入仓库创建页面。\n填写仓库名，格式必须为&lt;用户名&gt;.github.io，然后点击Create repository。\n\n\n四、配置 GitHub SSH key之所以需要进行相关配置，是因为我们首先要在本地搭建 Hexo 框架，编写博客内容，并将其编译为 HTML 页面后上传到 GitHub 仓库。在本地与 GitHub 进行连接和代码推送时，需要借助 Git 工具完成操作，而这些操作必须具备账户的访问权限。获取权限通常有两种方式：一种是通过 Personal Access Token（即 GitHub 提供的访问密钥）；另一种是本文所采用的方法。相比之下，本文介绍的方式更加便捷高效，强烈推荐使用。\n打开 Git Bash，输入命令：\nssh-keygen -t rsa -C &quot;user.email&quot; # user.email 为GitHub 上注册的邮箱\n\n随后连续按三次回车即可，默认情况下无需单独设置密码。接下来需要检查本地是否已经生成 SSH 密钥。打开用户主目录 C:\\Users\\username\\，找到其中的 .ssh 文件夹（该文件夹位于 C 盘的用户目录下），进入后即可查看相关密钥文件。\n\n\n然后找到生成的 .ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制。其中 id_rsa 是私钥不能泄露，id_rsa.pub 是公钥可以放心告诉他人。\n在 GitHub的 Settings 中点击 SSH and GPG keys 选项打开新建页面，新建一个 SSH Key。\n\n\nTitle 为标题，任意填即可，将刚刚复制的 id_rsa.pub 内容粘贴进去，最后点击 Add SSH key。在 Git Bash 中检测 GitHub 公钥设置是否成功，输入如下命令：\nssh -T git@github.com\n\n验证是否连接成功，连接成功的话，显示如下：\n\n\n五、安装Hexo1. Hexo 原理由于 GitHub Pages 只能托管静态文件，而博客除了文章正文外，还包含文章列表、分类、标签、分页等结构化内容。如果每次发布新文章都需要手动更新目录和相关链接，工作量将十分繁琐。Hexo 的作用正是在于此：它将所有 Markdown 文件统一存放在本地，每次写完文章后，只需执行相应命令即可自动批量生成完整的静态页面，最后再将更新后的文件提交到 GitHub 即可，大大提升了博客维护的效率。\n2. 安装与初始化在 Git Bash 中输入以下命令：\nnpm install -g hexo-cli # 此命令完成对 hexo 的安装\n\n安装完成后，在电脑的某个地方新建一个文件夹（名字可以随便取）专门用于存放博客代码，比如我的是 D:\\workspace\\myblog\\hexo-blog，由于这个文件夹将来存放博客的所有内容和素材，以及所有的博客操作都会在其中完成，所以最好不要随便放。\n进入新建的博客目录，输入如下命令：\nhexo init   # 该命令完成 hexo 在本地博客目录的初始化\n\n\n\n3. 生成静态文件在 Git Bash 中输入以下命令：\nhexo g   # 生成静态文件\n\n执行以上命令后，Hexo 就会在 public 文件夹中生成相关的 html 文件，这些文件将来都是要提交到 GitHub 上的 username.github.io 的仓库中去的。\n4. 本体预览在 Git Bash 输入以下命令：\nhexo s # 开启本地预览\n\nhexo s 是开启本地预览服务，打开浏览器访问 http://localhost:4000 即可看到内容，Ctrl+C 停止本地预览。本地预览可以实时查看博客的编辑情况，待博客写完后一起部署到 GitHub 上。\n第一次初始化的时候 hexo 已经帮我们写了一篇名为 Hello World 的文章。\n六、推送到GitHub1. 配置站点配置文件hexo 有 2 种 _config.yml 文件，一个是根目录下的全局的 _config.yml，一个是各个主题 theme 下的 _config.yml。将前者称为站点配置文件， 后者称为主题配置文件。\n打开根目录下站点配置文件 _config.yml，配置有关 deploy 的部分：\n# Deployment## Docs: https://hexo.io/docs/one-command-deploymentdeploy:  type: git  repo: git@github.com:fanlumaster/你的用户名.github.io.git  branch: main\n\n2. 安装插件在 Git Bash 中输入以下命令：\nnpm install hexo-deployer-git --save   # 安装部署插件\n\n如果不进行上述操作，直接使用 hexo d 部署到 GitHub，将会报错。\n3. 修改配置git config --global core.safecrlf false\n\n这个必须执行，不然使用推送必报错\n4. 部署到 GitHub在 Git Bash 中输入以下命令：\nhexo d\n\n部署成功后，打开对应的网址 https://username.github.io，如果出现了和本地预览一样的效果，那么，表明部署成功。\n","categories":["教程","Hexo"],"tags":["Hexo","GitHub"]},{"title":"集群、分布式、微服务的概念及异同","url":"/2025/08/30/post003/","content":"集群、分布式、微服务的概念及异同集群集群是指将多台服务器集中在一起，每台服务器都实现相同的业务，做相同的事；但是每台服务器并不是缺一不可，存在的主要作用是缓解并发能力和单点故障转移问题。\n分布式分布式服务是指多台服务器集中在一起，服务是分散部署在不同的机器上；每台机器都实现总体中的不同业务，做不同的事情；一个服务可能负责几个功能，是一种面向SOA的架构；各分开部署的部分彼此通过各种通讯协议交互信息，并且每台服务器都缺一不可，如果某台服务器故障，则部分功能缺失，或者导致整体无法运行；分布式存在的主要作用是大幅度的提高效率，缓解服务器的访问和存储压力。\n将一个大的系统划分为多个业务模块，业务模块分别部署到不同的机器上，各个业务模块之间通过接口进行数据交互。\n微服务微服务的概念和分布式比较相似，微服务是一种架构风格；简单来说微服务就是很小的服务，小到一个服务只对应一个单一的功能；每个微服务仅关注于完成一件任务并很好地完成该任务，这个服务可以单独部署运行；各个服务之间是松耦合的，服务之间可以通过RPC来相互交互；微服务与分布式还有一点区别是：微服务的应用不一定是分散在单个服务器上，它也可以是同一个服务器。       \n微服务相比分布式服务来说，它的粒度更小，服务之间耦合度更低，敏捷性也更高；但服务微服务化后带来的挑战也是显而易见的，例如服务力度小，数量大，后期运维难度增大等。\n","categories":["微服务"],"tags":["微服务"]},{"title":"Canal+MQ技术方案解析","url":"/2025/09/10/post004/","content":"Canal+MQ技术方案解析这是一个典型的数据异构和系统解耦方案，核心思想是将数据库的变更实时捕获，并以消息的形式广播出去，供其他消费系统进行处理。\n\n一、核心思想：从“拉”到“推”的转变在传统的架构中，如果一个业务系统（比如订单系统）的数据需要被其他系统（如数据分析系统、搜索引擎、缓存系统）使用，通常有两种方式：\n\n定时轮询：其他系统每隔一段时间（如每分钟）去数据库查询一次，看看有没有新数据。这种方式延迟高、数据库压力大、效率低下。这是一种“拉”模式。\n业务代码双写：在订单系统创建订单的代码里，不仅写数据库，还要调用其他系统的接口。这种方式耦合度极高，订单系统需要知道所有下游系统的存在，任何一个下游系统出问题都可能影响主流程。\n\nCanal + MQ 方案彻底改变了这个模式，它变成了“推”模式：数据库一旦发生变更，Canal会立刻知道，并把这个变更事件推送到消息队列中。下游系统只需要订阅MQ，就能实时收到变更通知，进行处理。\n\n二、方案核心组件解析这个方案主要由三个关键组件构成：\n1. 数据库通常是 MySQL。Canal的核心原理是将自己伪装成一个MySQL的从库。它利用了MySQL主从复制机制中的 binlog (二进制日志)。\n\n什么是 Binlog？ Binlog是MySQL服务器记录所有数据变更操作的日志文件（如 INSERT, UPDATE, DELETE）。主从复制就是主库把Binlog发给从库，从库重放这些日志来保持数据同步。\n开启Binlog：要使用Canal，必须先在MySQL中开启Binlog功能。\n\n2. CanalCanal是阿里巴巴开源的一个项目，它的作用就是解析数据库的Binlog。\n\n工作原理：\n\nCanal服务器连接到MySQL数据库，模拟成一个Slave。\n它向MySQL主库发送一个dump协议请求，请求从指定的Binlog位置开始获取日志。\nMySQL主库收到请求后，开始将Binlog事件推送给Canal服务器。\nCanal服务器接收到原始的Binlog数据后，会将其解析成结构化的、易于理解的消息格式（如JSON或Protobuf）。\n解析后的消息包含了变更的数据库、表、事件类型（INSERT&#x2F;UPDATE&#x2F;DELETE）以及变更前后的数据。\n\n\nCanal的角色：它是一个数据管道或数据同步中间件，负责将数据库的增量数据“搬运”出来。\n\n\n3. 消息队列MQ是整个方案的“消息总线”，负责解耦和削峰填谷。常用的MQ有：\n\nKafka: 高吞吐量，适合大数据场景，如日志收集、流式处理。\n\nRocketMQ: 阿里巴巴开源，功能丰富，支持事务消息等高级特性，在金融和电商场景中应用广泛。\n\nRabbitMQ: 轻量级，路由功能强大，适合复杂的业务逻辑路由。\n\nMQ的角色：\n\n解耦：Canal只管把数据发给MQ，不用关心谁在消费。下游系统也只管从MQ消费，不用关心数据是怎么来的。Canal和消费者之间完全解耦。\n削峰填谷：如果某一瞬间数据库有大量写入（如大促活动），Canal会产生大量消息。消费者可以按照自己的处理能力从MQ中拉取消息，避免被流量洪峰冲垮。\n广播：一个数据库变更事件，可以被多个不同的消费者系统同时消费，实现一份数据多处利用。\n\n\n\n\n三、完整工作流程下面我们以一个“新用户注册后，需要同步到ES和发送欢迎邮件”的场景为例，梳理一下完整的流程。\n\n准备工作：\n\n开启MySQL的Binlog。\n部署Canal Server，并配置好要连接的MySQL数据库信息。\n部署一个MQ（如Kafka），并创建一个Topic（如 user_binlog）。\n配置Canal Adapter，将解析后的Binlog数据发送到Kafka的 user_binlog Topic中。\n\n\n数据变更：\n\n一个新用户在App上注册，业务服务器向MySQL的 user 表中 INSERT 了一条新记录。\nMySQL将这条 INSERT 操作记录到Binlog中。\n\n\nCanal捕获与解析：\n\nCanal作为MySQL的“伪从库”，实时获取到这条Binlog。\n\nCanal解析这条Binlog，将其转换成一个结构化的消息，内容可能像这样：\n&#123;  &quot;database&quot;: &quot;user_db&quot;,  &quot;table&quot;: &quot;user&quot;,  &quot;type&quot;: &quot;INSERT&quot;,  &quot;data&quot;: [    &#123; &quot;id&quot;: 123, &quot;name&quot;: &quot;张三&quot;, &quot;email&quot;: &quot;zhangsan@example.com&quot; &#125;  ]&#125;\n\n\n发送到MQ：\n\nCanal Adapter将这个JSON消息发送到预先配置好的Kafka Topic user_binlog 中。\n\n\n下游消费者处理：\n\n**消费者A (ES同步服务)**：订阅了 user_binlog Topic。它收到消息后，解析出用户数据，然后调用Elasticsearch的API，将这个新用户的信息写入到ES索引中，以支持后续的搜索功能。\n**消费者B (邮件服务)**：也订阅了 user_binlog Topic。它收到消息后，解析出用户的邮箱地址，然后调用邮件发送接口，给“张三”发送一封欢迎邮件。\n\n\n\n\n四、优缺点分析优点\n解耦：核心优势。业务数据库和下游系统之间完全解耦，互不影响。\n实时性高：基于Binlog，数据延迟可以做到秒级甚至毫秒级。\n对业务代码无侵入：业务系统完全不需要知道Canal和MQ的存在，只需要专注于自身业务逻辑。\n数据可靠性：MQ提供了持久化机制，即使消费者系统宕机，消息也不会丢失，待系统恢复后可以继续消费。\n扩展性强：可以轻松增加新的消费者系统，只需订阅MQ即可，无需改动任何现有系统。\n\n缺点\n架构复杂度增加：引入了Canal和MQ，需要额外部署和维护这两个中间件，对运维能力有更高要求。\n数据一致性挑战：这是一个经典问题。如果业务事务提交成功，但Canal解析或MQ发送失败，就会导致数据不一致。虽然Canal和MQ有重试机制，但在极端情况下仍需考虑最终一致性的补偿方案。\n只能获取增量数据：Canal只能同步增量（变更）的数据。对于存量数据的全量同步，需要配合其他工具（如DataX）或自己编写脚本先做一次初始化。\n\n五、典型应用场景\n数据库到搜索引擎的实时同步：将MySQL、Oracle中的数据实时同步到Elasticsearch或Solr，提供实时搜索能力。\n构建数据仓库&#x2F;数据湖：将业务库的变更数据实时流入数据仓库（如ClickHouse）或数据湖，进行实时数据分析。\n缓存失效&#x2F;更新：当数据库数据变更时，通过此方案通知缓存系统（如Redis），删除或更新对应的缓存，解决缓存与数据库不一致的问题。\n微服务间的数据同步：在微服务架构中，一个服务的数据变更可能需要通知其他服务，Canal+MQ是一种优雅的异步通信方案。\n业务系统解耦：将核心业务流程和非核心流程（如日志、报表、通知）解耦。\n\n","categories":["消息队列"],"tags":["Canal","MQ"]},{"title":"Deque（双端队列）的常见实现类","url":"/2025/09/11/post005/","content":"Deque（双端队列）的常见实现类Deque（双端队列）接口在 Java 中有几个常见的实现类，每个都有其特定的用途和性能特点。Deque 的主要实现类有两个：**ArrayDeque** 和 **LinkedList**。此外，还有一个并发实现类 **ConcurrentLinkedDeque**。\n\n1. ArrayDeque - 数组双端队列这是 Deque 最常用、最通用的实现。\n\n内部数据结构：可动态扩容的数组。\n工作原理：它内部维护一个数组，并通过两个指针（head 和 tail）来标记队列的头和尾。当数组空间不足时，会进行扩容（通常容量翻倍）。\n性能特点：\n在两端添加、删除、获取元素的时间复杂度都是 **O(1)**，非常快。\n在中间插入或删除元素需要移动数组元素，时间复杂度为 **O(n)**。\n\n\n内存开销：较小。因为它只存储元素本身，没有额外的指针开销。\n线程安全：不安全。如果在多线程环境下使用，需要外部进行同步控制。\n适用场景：\n作为栈使用（push, pop）。\n作为普通队列使用（add, poll）。\n绝大多数单线程环境下的双端队列需求。\n\n\n\n\n2. LinkedList - 链表双端队列LinkedList 是一个“多面手”，它同时实现了 List 接口和 Deque 接口。\n\n内部数据结构：双向链表。每个节点都包含数据、指向前一个节点的指针和指向后一个节点的指针。\n工作原理：通过修改节点间的指针关系来添加或删除元素。\n性能特点：\n在两端添加、删除元素的时间复杂度是 **O(1)**。\n在中间插入或删除元素非常高效，也是 **O(1)**（前提是已经找到了要插入&#x2F;删除的位置）。\n随机访问（通过索引 get(i)）很慢，需要从头或尾开始遍历，时间复杂度为 **O(n)**。\n\n\n内存开销：较大。每个元素都需要额外的空间存储前后节点的指针。\n线程安全：不安全。\n适用场景：\n当你需要频繁在列表中间进行插入和删除操作时。\n当你需要一个既支持 List 操作（按索引访问）又支持 Deque 操作的结构时（但要注意其随机访问性能差）。\n\n\n\n\n3. ConcurrentLinkedDeque - 并发双端队列这是 java.util.concurrent 包下的一个实现，专为高并发环境设计。\n\n内部数据结构：基于链表。\n工作原理：使用 CAS（Compare-And-Swap） 无锁算法来实现线程安全。\n性能特点：\n在高并发场景下，性能远优于使用 Collections.synchronizedDeque() 包装的队列。\n操作（如 add, poll）通常是非阻塞的，不会因为锁竞争而挂起线程。\n不能插入 null 元素。\n**size() 方法的性能可能不是 O(1)**，因为它需要遍历链表来计算准确大小，在并发环境下这是一个耗时操作。应尽量避免调用。\n\n\n内存开销：较大（链表结构）。\n线程安全：安全。并且是高效的、无锁的线程安全。\n适用场景：\n高并发的生产者-消费者模型。\n任何需要多线程安全访问双端队列的场景。\n\n\n\n\n总结与对比\n\n\n特性\nArrayDeque\nLinkedList\nConcurrentLinkedDeque\n\n\n\n数据结构\n数组\n双向链表\n链表 (CAS)\n\n\n主要用途\n栈、队列（首选）\n频繁中间插入&#x2F;删除\n高并发场景\n\n\n两端操作性能\nO(1) (极快)\nO(1) (快)\nO(1) (并发下快)\n\n\n中间插入&#x2F;删除\nO(n) (慢)\nO(1) (快)\nO(1) (并发下快)\n\n\n随机访问\nO(1) (快)\nO(n) (慢)\nO(n) (慢)\n\n\n内存开销\n小\n大\n大\n\n\n线程安全\n否\n否\n是 (无锁)\n\n\n如何选择？\n默认选择：**ArrayDeque**。当你需要一个栈或队列时，它几乎总是最好的选择。\n需要频繁在中间操作：考虑 **LinkedList**。\n多线程高并发环境：必须使用 **ConcurrentLinkedDeque**。\n\n另外，不要使用 Java 1.0 的 Stack 类，它已经被 ArrayDeque 完全取代。如果需要一个线程安全的栈，可以使用 Collections.synchronizedDeque(new ArrayDeque&lt;&gt;())。\n首选 ArrayDeque 作为栈和队列的实现\nDeque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;();Deque&lt;Integer&gt; queue = new ArrayDeque&lt;&gt;();\n\n","categories":["Java"],"tags":["Java","Deque"]},{"title":"windows安装两个或多个JDK，并实现自由切换","url":"/2025/09/15/post006/","content":"windows安装两个或多个JDK，并实现自由切换前言在工作中遇到不同的项目需要使用不同版本的JDK，搜索查询资料后总结如下，按照这种方式可以安装两个或者更多版本（根据自己需求下载安装即可）\n一、前期准备我这里用两个 JDK 来做演示，分别是 JDK17 和 JDK21 (本人已安装 JDK17，所以这里只演示 JDK21 的安装)。首先去官网下载所需要的对应版本的 JDK 安装包或者压缩包。\n\n\n\n\n二、安装下载完成后，安装包的话直接下一步安装到自己想要的目录即可，压缩包的话解压到自己想要的目录即可。\n三、注意事项解压版跳过此项\n如果是安装版，请务必到以下位置删除这两个文件夹\nC:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapathC:\\Program Files\\Common Files\\Oracle\\Java\\javapath\n\n\n\n四、配置环境变量\n在系统变量中新建一个CLASSPATH，添加变量值如下\n.;%JAVA_HOME%\\lib;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar\n\n\n\n在系统变量里面找到Path选项，编辑，加入以下变量值\n%JAVA_HOME%\\bin%JAVA_HOME%\\jre\\bin\n\n\n\n在系统变量里新建3个 JAVA_HOME\n\n\n\n变量\n值\n\n\n\nJAVA_HOME\n%JAVA17_HOME% （这里这样写是使用JAVA17）\n\n\nJAVA17_HOME\nD:\\Java\\jdk17（写自己的java17的安装目录）\n\n\nJAVA21_HOME\nD:\\Java\\jdk21（写自己的java21的安装目录）\n\n\n\n\nJDK的安装目录复制到bin的上一级就可以了\n\n\n\n\n\n\n五、测试\n切换JDK版本\n修改如下图所示的值，修改为你想用的JDK的版本即可\n\n\n\n\n\n测试\nWin + R 输入cmd打开命令提示符，键入\njava -version\n\n就可以查看你现在所启用的jdk版本信息（注意：修改完环境变量后，必须重新打开一个新的cmd窗口进行查看！！！）\n\n\n","categories":["Java","JDK"],"tags":["JDK"]},{"title":"Redis 知识点总结","url":"/2025/10/02/post008/","content":"Redis 知识点总结1. Redis 中常见的数据类型有哪些？\n字符串（String）介绍：这是 Redis 最基本的数据类型，它可以存储字符串、整数或者浮点数。最大长度 512MB\n\n应用场景：常用于缓存、计数器、分布式锁等。例如，你可以把网页的缓存数据以字符串形式存储在 Redis 中，这样下次访问时可以直接从 Redis 获取，加快访问速度；也可以用它来实现一个简单的计数器，对某个操作的次数进行计数。譬如点赞\n\n哈希（Hash）介绍：是一个键值对的集合，类似于 Java 中的 HashMap 或者 Python 中的字典。每个哈希可以存储多个字段 - 值对。\n\n应用场景：适合存储对象，比如用户信息，每个用户的不同属性（如姓名、年龄、邮箱等）可以作为哈希的字段，对应的值就是属性值。\n\n列表（List）介绍：是一个简单的字符串列表，按照插入顺序排序。可以在列表的头部（左边）或者尾部（右边）插入元素。双向链表\n\n应用场景：常用于消息队列、最新消息列表等。例如，在一个社交应用中，可以用列表存储用户的最新动态，新的动态不断添加到列表头部。\n\n集合（Set）介绍：是一个无序且唯一的字符串集合。\n\n应用场景：适用于去重、交集、并集、差集等操作。比如，在一个网站中，可以用集合存储用户的标签，通过集合的操作找出有相同标签的用户。\n\n有序集合（Sorted Set）介绍：和集合类似，也是唯一的，但每个成员都关联了一个分数（score），根据分数进行排序。底层使用跳表实现\n\n应用场景：常用于实时排行榜、热门列表等。例如，在游戏中，可以用有序集合存储玩家的积分，根据积分进行排名。\n2. Redis 为什么这么快？\n基于内存操作Redis 是将数据存储在内存中的，相比于传统的磁盘存储数据库，内存的读写速度要快得多。磁盘 I&#x2F;O 操作是比较耗时的，而内存操作可以在极短的时间内完成，大大提高了数据的读写效率。\n单线程模型Redis 使用单线程来处理客户端的请求。虽然单线程听起来可能会限制性能，但在 Redis 中却有其优势。单线程避免了多线程之间的上下文切换和锁竞争问题，这些问题在多线程环境中会消耗大量的 CPU 资源和时间。而且 Redis 的操作都是原子性的，单线程可以保证操作的原子性，避免了并发问题。\n高效的数据结构Redis 实现了多种高效的数据结构，如哈希表、跳跃表等。这些数据结构在插入、查找和删除操作上具有很高的效率。例如，哈希表的查找和插入操作的平均时间复杂度是 O (1)，跳跃表在有序集合的插入、删除和查找操作上的平均时间复杂度是 O (logn)。\n非阻塞 I&#x2F;O 模型Redis 使用了非阻塞 I&#x2F;O 模型（如 Linux 下的 epoll）。这种模型可以同时处理多个客户端的请求，而不会因为某个请求的阻塞而影响其他请求的处理。当一个客户端的请求需要进行 I&#x2F;O 操作时，Redis 不会等待操作完成，而是继续处理其他请求，等 I&#x2F;O 操作完成后再进行相应的处理，从而提高了系统的并发处理能力。\n\n3. 为什么 Redis 设计为单线程？6.0 版本为何引入多线程？\n为什么 Redis 设计为单线程\n\n避免并发问题：多线程编程中会存在很多并发问题，如锁竞争、死锁等。这些问题会增加代码的复杂度，并且容易引入难以调试的 bug。Redis 采用单线程模型，避免了这些并发问题，使得代码更加简洁、稳定，易于维护。减少上下文切换开销：在多线程环境中，CPU 需要在不同的线程之间进行上下文切换，这个过程会消耗一定的时间和 CPU 资源。单线程模型避免了上下文切换，提高了 CPU 的利用率。保证操作的原子性：Redis 的很多操作都是原子性的，单线程可以保证这些操作在执行过程中不会被其他线程打断，从而保证了数据的一致性和完整性。\n\n6.0 版本为何引入多线程\n\n网络 I&#x2F;O 瓶颈：虽然 Redis 的核心操作是单线程的，但在处理大量客户端请求时，网络 I&#x2F;O 可能会成为瓶颈。尤其是在高并发场景下，单线程处理网络 I&#x2F;O 可能无法充分利用服务器的多核 CPU 资源。提高并发处理能力：Redis 6.0 引入的多线程主要是用于处理网络 I&#x2F;O 操作，而核心的命令执行仍然是单线程的。通过多线程处理网络 I&#x2F;O，可以提高 Redis 对客户端请求的处理速度，充分利用多核 CPU 的优势，从而提高系统的并发处理能力。例如，在处理大量的读写请求时，多线程可以同时处理多个客户端的连接和数据传输，减少了请求的等待时间。\n","categories":["Redis"],"tags":["Redis"]},{"title":"MySQL 知识点总结","url":"/2025/10/01/post007/","content":"MySQL 知识点总结1. MySQL 的索引类型有哪些?MySQL 里的索引就像是书的目录，能帮数据库快速找到你要的数据。以下是各种索引类型的通俗解释：\n按数据结构分\nB + 树索引：最常用的一种，数据像在一棵树上分层存放，能快速定位范围数据，比如查找某个分数区间内的学生成绩。\n哈希索引：通过把数据变成哈希值来建立索引，查找速度特别快，但只适合精确查找，比如根据身份证号找特定的人，要是找某个范围的就不行了。\n倒排索引（全文索引）：主要用来处理文本数据，比如在一篇文章里找特定的词，它会记录每个词在哪些文档里出现过。\nR - 树索引：用于处理多维空间数据，比如地图上查找某个区域内的所有店铺。\n\n基于 InnoDB B + 树索引分\n聚簇索引：数据和索引是放在一起的，就像书的正文和目录装订在一起，一般主键会默认是聚簇索引，找数据时速度快。\n非聚簇索引：数据和索引分开存放，就像书的正文和目录分开，查找到索引后还得再去查数据。\n\n按索引性质分\n普通索引：最基本的索引，用来加快查询速度，比如在学生表中给姓名字段建普通索引，查特定姓名的学生更快。\n主键索引：特殊的唯一索引，每个表只能有一个，就像每个人的身份证号，不能重复且必须有，用来唯一标识一行数据。\n联合索引：把多个字段组合起来建索引，比如在学生表中把班级和成绩两个字段建联合索引，查某个班级特定成绩范围的学生时会更高效。\n唯一索引：保证索引列的值不能重复，但可以有 NULL 值，比如员工表中员工编号字段建唯一索引。\n全文索引：上面按数据结构分的时候讲过，用于在文本中快速查找特定词汇。\n空间索引：和 R - 树索引类似，用于处理地理空间等数据，比如查找某个城市内的所有加油站。\n\n2.MySQL InnoDB 引擎中的聚簇索引和非聚簇索引有什么区别?聚簇索引\n“索引叶子结点存储的是数据行，可以直接访问完整数据”：就好比一本书，它的目录后面直接跟着对应的正文内容。在聚簇索引里，索引的最底层（叶子结点）存的不只是索引信息，而是整行的数据。所以当你通过聚簇索引去查找数据时，一下子就能拿到完整的一行数据，不用再去别的地方找。\n“每个表只能有一个聚簇索引，通常是主键索引，适合范围查询和排序”：每个表就像一本独特的书，只能有一份这种目录和正文紧密相连的结构，也就是只能有一个聚簇索引。一般情况下，主键就充当了这个聚簇索引，因为主键能唯一确定一行数据。如果要查找某个范围的数据，比如找成绩在 80 - 90 分之间的学生记录，或者要对数据进行排序，聚簇索引处理起来就比较高效，因为数据在物理存储上是按照一定顺序排列的。\n\n非聚簇索引\n“索引叶子节点存储的是数据行的主键和对应的索引列，需通过主键才能访问完整的数据行”：非聚簇索引像是另外单独的一个小目录，这个小目录里记录的是数据行的主键信息以及对应的索引列信息。当你通过这个小目录找到对应的主键后，还得再去聚簇索引那里，根据主键把完整的数据行找出来，就好像你先在小目录里查到页码，还得去书的正文里找具体内容。\n“一个表可以有多个非聚簇索引（称之为非主键索引、辅助索引、二级索引），适用于快速查找特定列的数据”：一个表可以有很多个这样的小目录，也就是可以有多个非聚簇索引。当你只需要查找表中的某一个或几个特定列的数据时，用非聚簇索引就比较快。比如你只想查学生表中的学生姓名，在姓名字段上建了非聚簇索引的话，就能快速定位到这些姓名信息。\n\n3. MySQL 的存储引擎有哪些? 它们之间有什么区别?InnoDB\n支持事务、行级锁和外键：事务就像一个打包任务，要么全成功，要么全失败，比如转账时同时增减双方账户金额。行级锁是只锁定要处理的那一行数据，这样别人还能操作其他行，就像你在图书馆占一个座位，不妨碍别人坐其他座位。外键能把不同表的数据关联起来，比如学生表和成绩表通过学号关联。\n提供高并发性能，适用于高负载的 OLTP 应用：可以同时处理很多人的操作请求，像银行系统很多人同时转账、查询等。\n数据以聚集索引的方式存储，提高检索效率：数据存放方式让查找速度变快，就像书的目录和正文放一起，找内容方便。\n\nMyISAM\n不支持事务和外键，使用表级锁：没有事务打包功能，也不能关联不同表数据。表级锁是锁定整张表，就像你把整个图书馆占了，别人都不能用。\n适合读取多、更新少的场景，如数据仓库：如果只是经常查数据，很少改数据，用它就挺好，像公司用来分析历史数据的数据仓库。\n具有较高的读性能和较快的表级锁定：读数据速度快，锁定表也快。\n\nMEMORY\n数据存储在内存中，速度快，但数据在服务器重启后丢失：数据放在内存里，访问就像在眼前拿东西一样快。不过服务器一重启，内存里的数据就没了，就像电脑重启后没保存的临时文件没了。\n适用于临时数据存储或快速缓存：比如存临时计算结果，或者做快速缓存来加快访问。\n\nNDB (NDCluster)\n支持高可用性和数据分布，适合大规模分布式应用：能保证服务一直可用，数据还能分散存，适合像大型电商平台那种大规模分布式系统。\n提供行级锁和自动分区：行级锁不影响别人操作其他行，自动分区把数据分到不同地方存，提高性能。\n\nARCHIVE\n用于存储大量历史数据，支持高效的插入和压缩：适合存公司多年的历史订单等大量历史数据，存数据快还能压缩节省空间。\n不支持索引，适合日志数据存储：不能用索引快速查找，但存日志数据很合适，反正日志主要是按顺序记录。\n\n","categories":["MySQL"],"tags":["MySQL"]},{"title":"test-article","url":"/2025/08/23/test-article/","content":"这是一篇测试文章欢迎观看\n\n","categories":["Java","Python"],"tags":["原创"]}]